{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img,img_to_array\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.initializers import RandomNormal\n",
    "#from keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard,ReduceLROnPlateau\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers import *\n",
    "from keras import backend as K\n",
    "from keras.models import model_from_json\n",
    "from matplotlib import cm as CM\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import scipy.io as io\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import h5py as h5\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import sys\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/u/s/s/ssrinivasan/private/CS639Project/CS639-Final-Project/'\n",
    "train = os.path.join(root,'train','sequences')\n",
    "test = os.path.join(root,'test','sequences')\n",
    "path_sets = [train, test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths_test = []\n",
    "for root, dirs, files in os.walk(path_sets[1]):\n",
    "        for img in files:\n",
    "                img_paths_test.append(os.path.join(root, img))\n",
    "test_sum = len(img_paths_test)\n",
    "\n",
    "# img_paths_test = []\n",
    "# for img_path in os.path.join(path_sets[1], '*.jpg'):\n",
    "#         img_paths_test.append(str(img_path))\n",
    "# print(\"Test image importation .. Total images : \",len(img_paths_test))\n",
    "# test_sum = len(img_paths_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths_train = []\n",
    "for root, dirs, files in os.walk(path_sets[0]):\n",
    "        for img in files:\n",
    "                img_paths_train.append(os.path.join(root, img))\n",
    "train_sum = len(img_paths_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_img(path):\n",
    "    #Function to load,normalize and return image \n",
    "    im = Image.open(path).convert('RGB')\n",
    "    \"\"\"width, height = im.size \n",
    "    newsize = (width // 2, height //2)\n",
    "    im = im.resize(newsize)\"\"\"\n",
    "    im = np.array(im)\n",
    "    \n",
    "    im = im/255.0\n",
    "    \n",
    "    im[:,:,0]=(im[:,:,0]-0.485)/0.229\n",
    "    im[:,:,1]=(im[:,:,1]-0.456)/0.224\n",
    "    im[:,:,2]=(im[:,:,2]-0.406)/0.225\n",
    "\n",
    "    #print(im.shape)\n",
    "    #im = np.expand_dims(im,axis  = 0)\n",
    "    return im\n",
    "\n",
    "def get_input(path):\n",
    "    #print(path)\n",
    "    path = path[0] \n",
    "    img = create_img(path)\n",
    "    return(img)\n",
    "\n",
    "def get_output(path):\n",
    "    #import target\n",
    "    #resize target\n",
    "    #print(path)\n",
    "    gt_file = h5.File(path,'r')\n",
    "    target = np.asarray(gt_file['density'])\n",
    "    img = cv2.resize(target,(int(target.shape[1]//8),int(target.shape[0]//8)),interpolation = cv2.INTER_CUBIC)*64\n",
    "    img = np.expand_dims(img,axis  = 2)\n",
    "    #print(img.shape)\n",
    "    return img\n",
    "\n",
    "def preprocess_input(image,target):\n",
    "    #crop image\n",
    "    #crop target\n",
    "    #resize target\n",
    "    crop_size = (int(image.shape[0]/2),int(image.shape[1]/2))\n",
    "    #imm = np.resize(image,((image.shape[0]//2),int(image.shape[1]//2)))\n",
    "    #tar = np.resize(target,((image.shape[0]//2),int(image.shape[1]//2)))\n",
    "    if random.randint(0,9)<= -1:            \n",
    "            dx = int(random.randint(0,1)*image.shape[0]*1./2)\n",
    "            dy = int(random.randint(0,1)*image.shape[1]*1./2)\n",
    "    else:\n",
    "            dx = int(random.random()*image.shape[0]*1./2)\n",
    "            dy = int(random.random()*image.shape[1]*1./2)\n",
    "\n",
    "    #print(crop_size , dx , dy)\n",
    "    img = image[dx : crop_size[0]+dx , dy:crop_size[1]+dy]\n",
    "    \n",
    "    target_aug = target[dx:crop_size[0]+dx,dy:crop_size[1]+dy]\n",
    "    #print(img.shape)\n",
    "\n",
    "    return(img,target_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image data generator \n",
    "def image_generator(files, batch_size=64):\n",
    "    while True:        \n",
    "        input_path = np.random.choice(a = files, size = batch_size)\n",
    "        #print(input_path)\n",
    "        batch_input = []\n",
    "        batch_output = [] \n",
    "          \n",
    "        #for input_path in batch_paths:\n",
    "        \n",
    "        inputt = get_input(input_path)\n",
    "        output = get_output(input_path[0].replace('.jpg','.h5').replace('sequences','ground_truth') )\n",
    "       \n",
    "        batch_input += [inputt]\n",
    "        batch_output += [output]\n",
    "\n",
    "        batch_x = np.append(batch_x, batch_input)\n",
    "        batch_y = np.append(batch_y, batch_output)\n",
    "        yield (batch_x, batch_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mod(model , str1 , str2):\n",
    "    model.save_weights(str1)\n",
    "    model_json = model.to_json()\n",
    "    with open(str2, \"w\") as json_file:\n",
    "        json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights_vgg(model):\n",
    "    #vgg =  VGG16(weights='imagenet', include_top=False)\n",
    "    \n",
    "    json_file = open('/u/s/s/ssrinivasan/private/CS639Project/CS639-Final-Project/CSRNet-keras/models/V66_16.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    loaded_model.load_weights(\"/u/s/s/ssrinivasan/private/CS639Project/CS639-Final-Project/CSRNet-keras/weights/VGG_16.h5\")\n",
    "    \n",
    "    vgg = loaded_model\n",
    "    \n",
    "    vgg_weights=[]                         \n",
    "    for layer in vgg.layers:\n",
    "        if('conv' in layer.name):\n",
    "            vgg_weights.append(layer.get_weights())\n",
    "    offset=0\n",
    "    i=0\n",
    "    while(i<10): \n",
    "        if('conv' in model.layers[i+offset].name):\n",
    "            model.layers[i+offset].set_weights(vgg_weights[i])\n",
    "            i=i+1\n",
    "            \n",
    "        else:\n",
    "            offset=offset+1\n",
    "\n",
    "    return (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance_loss(y_true, y_pred):\n",
    "    # Euclidean distance as a measure of loss (Loss function) \n",
    "    return K.sqrt(K.sum(K.square(y_pred - y_true), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_true, y_pred):\n",
    "    return abs(K.sum(y_true) - K.sum(y_pred))\n",
    "def mse(y_true, y_pred):\n",
    "    return tf.math.sqrt(K.sum(y_true) * K.sum(y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "def CrowdNet():  \n",
    "            #Variable Input Size\n",
    "            rows = None\n",
    "            cols = None\n",
    "            \n",
    "            #Batch Normalisation option\n",
    "            \n",
    "            batch_norm = 0\n",
    "            kernel = (3, 3)\n",
    "            init = RandomNormal(stddev=0.01)\n",
    "            model = Sequential() \n",
    "            #custom VGG:\n",
    "            \n",
    "            if(batch_norm):\n",
    "                model.add(Conv2D(64, kernel_size = kernel,  input_shape = (rows,cols,3),activation = 'relu', padding='same'))\n",
    "                model.add(BatchNormalization())\n",
    "                model.add(Conv2D(64, kernel_size = kernel,activation = 'relu', padding='same'))\n",
    "                model.add(BatchNormalization())\n",
    "                model.add(MaxPooling2D(strides=2))\n",
    "                model.add(Conv2D(128,kernel_size = kernel, activation = 'relu', padding='same'))#64\n",
    "                model.add(BatchNormalization())\n",
    "                model.add(Conv2D(128,kernel_size = kernel, activation = 'relu', padding='same'))\n",
    "                model.add(BatchNormalization())\n",
    "                model.add(MaxPooling2D(strides=2))\n",
    "                model.add(Conv2D(256,kernel_size = kernel, activation = 'relu', padding='same'))#128\n",
    "                model.add(BatchNormalization())\n",
    "                model.add(Conv2D(256,kernel_size = kernel, activation = 'relu', padding='same'))\n",
    "                model.add(BatchNormalization())\n",
    "                model.add(Conv2D(256,kernel_size = kernel, activation = 'relu', padding='same'))\n",
    "                model.add(BatchNormalization())\n",
    "                model.add(MaxPooling2D(strides=2))            \n",
    "                model.add(Conv2D(512, kernel_size = kernel,activation = 'relu', padding='same'))\n",
    "                model.add(BatchNormalization())\n",
    "                model.add(Conv2D(512, kernel_size = kernel,activation = 'relu', padding='same'))\n",
    "                model.add(BatchNormalization())\n",
    "                model.add(Conv2D(512, kernel_size = kernel,activation = 'relu', padding='same'))\n",
    "                \n",
    "            else:\n",
    "                model.add(Conv2D(64, kernel_size = kernel,activation = 'relu', padding='same',input_shape = (rows, cols, 3), kernel_initializer = init))\n",
    "                model.add(Conv2D(64, kernel_size = kernel,activation = 'relu', padding='same', kernel_initializer = init))\n",
    "                model.add(MaxPooling2D(strides=2))\n",
    "                model.add(Conv2D(128,kernel_size = kernel, activation = 'relu', padding='same', kernel_initializer = init))\n",
    "                model.add(Conv2D(128,kernel_size = kernel, activation = 'relu', padding='same', kernel_initializer = init))\n",
    "                model.add(MaxPooling2D(strides=2))\n",
    "                model.add(Conv2D(256,kernel_size = kernel, activation = 'relu', padding='same', kernel_initializer = init))\n",
    "                model.add(Conv2D(256,kernel_size = kernel, activation = 'relu', padding='same', kernel_initializer = init))\n",
    "                model.add(Conv2D(256,kernel_size = kernel, activation = 'relu', padding='same', kernel_initializer = init))\n",
    "                model.add(MaxPooling2D(strides=2))            \n",
    "                model.add(Conv2D(512, kernel_size = kernel,activation = 'relu', padding='same', kernel_initializer = init))\n",
    "                model.add(Conv2D(512, kernel_size = kernel,activation = 'relu', padding='same', kernel_initializer = init))\n",
    "                model.add(Conv2D(512, kernel_size = kernel,activation = 'relu', padding='same', kernel_initializer = init))\n",
    "            #Conv2D\n",
    "            model.add(Dropout(0.3))\n",
    "            model.add(Conv2D(512, (3, 3), activation='relu', dilation_rate = 2, kernel_initializer = init, padding = \"same\"))\n",
    "            model.add(Dropout(0.3))\n",
    "            model.add(Conv2D(256, (3, 3), activation='relu', dilation_rate = 2, kernel_initializer = init, padding = 'same'))\n",
    "            model.add(Dropout(0.1))\n",
    "            model.add(Conv2D(128, (3, 3), activation='relu', dilation_rate = 2, kernel_initializer = init, padding = 'same'))\n",
    "            model.add(Dropout(0.1))\n",
    "            model.add(Conv2D(64, (3, 3), activation='relu', dilation_rate = 2, kernel_initializer = init, padding = 'same'))\n",
    "            model.add(Conv2D(1, (1, 1), activation='relu', dilation_rate = 1, kernel_initializer = init, padding = 'same'))\n",
    "        \n",
    "            sgd = SGD(lr = 1e-7, decay = (5*1e-4), momentum = 0.95)\n",
    "            #model.compile(optimizer=sgd, loss=euclidean_distance_loss, metrics=['mse'])\n",
    "            #tf.keras.losses.Huber()\n",
    "            model.compile(optimizer=Adam(1e-5), loss='accuracy', metrics=[mae, \"mse\"])\n",
    "            #optimizer=Adam(1e-5)\n",
    "            model = init_weights_vgg(model)\n",
    "            \n",
    "            return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CrowdNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = './log/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(log_dir + \"best_weights.h5\", verbose=1, monitor='val_mae',save_freq='epoch', save_weights_only=True, save_best_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='mse', factor=0.2, patience=4, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "stopit = EarlyStopping(monitor=\"val_mae\",patience=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [checkpoint, reduce_lr, stopit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 1 #28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = image_generator(img_paths_train,batch)\n",
    "train_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_gen = image_generator(img_paths_test,batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr = 1e-7, decay = (5*1e-4), momentum = 0.95)\n",
    "#model.compile(optimizer=sgd, loss=euclidean_distance_loss, metrics=['mse'])\n",
    "#tf.keras.losses.CosineSimilarity(axis=1) =loss\n",
    "model.compile(optimizer=Adam(1e-5), loss='mae', metrics=[mae, \"mse\", 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit(train_gen,\n",
    "    steps_per_epoch=train_sum // batch,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=test_sum // batch,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    verbose = 1,\n",
    "    callbacks=callbacks\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = NUM_EPOCHS\n",
    "H=history\n",
    "plt.style.use(\"classic\")\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize = (12,4))\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "\n",
    "plt.title(\"Training Loss on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xticks(np.arange(0,N+2,5))\n",
    "\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plotLoss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = NUM_EPOCHS\n",
    "H=history\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize = (12,4))\n",
    "\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "\n",
    "plt.title(\"Training Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xticks(np.arange(0,N+2,5))\n",
    "#plt.yticks(np.arange(0,1,0.1))\n",
    "axes = plt.gca()\n",
    "#axes.xaxis.set_ticklabels(np.arange(0, N), rotation = 0, color = 'black', fontsize = 12,  verticalalignment = 'bottom')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plotAccuracy .png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = NUM_EPOCHS\n",
    "H=history\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize = (12,4))\n",
    "plt.plot(np.arange(0, N), H.history[\"mae\"], label=\"train_mae\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_mae\"], label=\"val_mae\")\n",
    "plt.plot(np.arange(0, N), H.history[\"mse\"], label=\"train_mse\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_mse\"], label=\"val_mse\")\n",
    "plt.title(\"Training MAE and MSE on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"MAE/MSE\")\n",
    "plt.xticks(np.arange(0,N+2,5))\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plotMAEMSE.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import scipy.io as io\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(img_pathss)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize = (12,4))\n",
    "plt.plot(y_true, 'b+', label = \"Ground truth\")\n",
    "plt.plot(y_pred, 'r>', label = \"Predection\")\n",
    "\n",
    "\n",
    "plt.title('Prediction vs GT')\n",
    "plt.xlabel(\"Test frames\")\n",
    "plt.ylabel(\"Number of persons\")\n",
    "plt.xticks(np.arange(0,N+20,20))\n",
    "\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig(\"plotPredectionGT.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(img_pathss)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize = (12,4))\n",
    "\n",
    "error = np.array(y_pred) - np.array(y_true)\n",
    "plt.plot(error, label = \"Counting error\")\n",
    "\n",
    "plt.title('Pred - GT, mean = {}, MAE={}'.format(\n",
    "    str(round(np.mean(error), 3)),\n",
    "    str(round(np.mean(np.abs(error)), 3))\n",
    "))\n",
    "plt.xlabel(\"Test frames\")\n",
    "plt.ylabel(\"Predection error\")\n",
    "plt.xticks(np.arange(0,N+20,20))\n",
    "\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plotLoss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = mean_absolute_error(np.array(y_true),np.array(y_pred))\n",
    "print(\"MAE : \" , ans )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}